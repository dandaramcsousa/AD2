---
title: "Predição de Votação de Deputados"
author: "Dandara Sousa"
date: "11 de dezembro de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(ggplot2)
library(readr)
library(dplyr) 

library(Amelia)
library(caret)

theme_set(theme_minimal())
```

Primeiramente, vamos inicializar nosso dataset. Nele contém dados dos deputados e a quantidade de votos. Como podemos ver mais abaixo há muita informação faltando e para não compremeter nossa predição iremos dar à essas partes o valor de zero.

```{r}
dataVotos <- read.csv("eleicoes2014.csv", encoding = "latin1")
missmap(dataVotos)


dataVotos <- dataVotos %>%
  mutate(
      recursos_de_pessoas_físicas = replace(recursos_de_pessoas_físicas,is.na(recursos_de_pessoas_físicas),0),
      recursos_de_pessoas_juridicas= replace(recursos_de_pessoas_juridicas,is.na(recursos_de_pessoas_juridicas),0),
      recursos_de_outros_candidatos.comites= replace(recursos_de_outros_candidatos.comites,is.na(recursos_de_outros_candidatos.comites),0),
      recursos_de_partidos = replace(recursos_de_partidos, is.na(recursos_de_partidos), 0),
      recursos_proprios = replace(recursos_proprios, is.na(recursos_proprios),0)
  )
```

O próximo passo para deixar os dados apropriados para nossa análise é excluir variáveis que previamente vimos que não influenciam para nosso caso.

```{r}
dataVotos.ajustado <- dataVotos %>%
  select(-nome, -sequencial_candidato, -numero_cadidato, -cargo, -setor_economico_despesa, -setor_economico_receita,  -partido, -UF)
```

_Separação em dados e treino:_  
Agora, vamos preparar nossos dados para nosso real objetivo hoje. Primeiro, vamos dividir nossos dados em dados para treino e dados para teste. Os dados para treino servirão para preparar nosso modelo para o teste (que intuitivamente será com os dados para testes).
```{r}
smp_size <- floor(.7*nrow(dataVotos.ajustado))
set.seed(123)
train_id <- sample(seq_len(nrow(dataVotos.ajustado)), size = smp_size)

dataVotos.treino <- dataVotos.ajustado[train_id,]
dataVotos.teste <- dataVotos.ajustado[-train_id,]
```

_Reamostragem:_  
Nesse momento vamos fazer a reamostragem dos nossos dados e, em seguida, vamos começar os modelos de regressão.
```{r}
dataVotos.control <- trainControl(method = "repeatedcv",
                                  number = 5,
                                  repeats = 5
                                  )

```

**Tunando (usando validação cruzada):**
  
  (i) um modelo de regressão Ridge  
  _modelo e cross validation:_
```{r}
data.model.ridge <- train(votos ~.,
                    data = dataVotos.treino,
                    method = "ridge"
                    )
model.cv.ridge <- train(votos ~ ., 
               data = dataVotos.treino,
               method = "ridge",
               trControl = dataVotos.control,
               preProcess = c('scale', 'center', 'nzv'),
               tuneLength = 5
               )
model.cv.ridge
```

  (ii) um modelo de regressão Lasso  
  _modelo e cross validation:_
```{r}
data.model.lasso <- train(votos ~.,
                    data = dataVotos.treino,
                    method = "lasso")
model.cv.lasso <- train(votos ~ ., 
               data = dataVotos.treino,
               method = "lasso",
               trControl = dataVotos.control,
               preProcess = c('scale', 'center', 'nzv'),
               tuneLength = 5
               )
model.cv.lasso
```
  
  (iii) um modelo KNN. 
 _modelo e validacao:_
```{r}
data.model.knn <- train(votos ~.,
                    data = dataVotos.treino,
                    method = "knn"
                    )
model.cv.knn <- train(votos ~ ., 
               data = dataVotos.treino,
               method = "knn",
               trControl = dataVotos.control,
               preProcess = c('scale', 'center', 'nzv'),
               tuneLength = 5
               )
model.cv.knn
```

  
 Usamos uma reamostragem com validação cruzada como vimos acima e os resultados foram:  

| . | Ridge | Lasso | KNN |  
|:---------:|:------:|:------:|:------:|
| final value[^1] | 0.1 | 0.3 | 13 |
| RSME | 36235.27 | 36806.54 | 33269.43 |
| Rsquared | 0.4418153 | 0.4299437 | 0.5059338 | 
| MAE | 12343.66 | 12424.53 | 10173.18 | 

Podemos ver que o RSME utilizado Ridge é melhor que com Lasso mas o melhor de todos é o que KNN apresenta. Porém o R² do Lasso é o melhor dentre os três modelos. E, novamente, KNN se destaca no valor de MAE.

**Comparação em termos do erro RMSE de validação cruzada.**
Para termos uma noção melhor do poder preditivo com nossos dados de teste, temos:

```{r}
rmse <- function(err) {
    sqrt(mean(err^2))
}

ridge.pred <- predict(model.cv.ridge, dataVotos.teste)
ridge.rmse <- rmse(ridge.pred - dataVotos.teste$votos)

lasso.pred <- predict(model.cv.lasso, dataVotos.teste)
lasso.rmse <- rmse(lasso.pred - dataVotos.teste$votos)

ridge.rmse
lasso.rmse
```
Vemos que para Ridge temos RMSE de `28887.08` e para Lasso `24974.48`. Sendo assim, vemos que o Lasso é ligeiramente menor que o Ridge a junto com a tabela mais acima percebemos que ambos tem um comportamento até que semelhante.

[^1]: Em Ridge o final value usado é o melhor lambda, em Lasso é fraction e com KNN é k.


**As variáveis mais importantes segundo o modelo de regressão Ridge e Lasso**

Para a importância das variáveis de cada modelo, vamos observar os seguintes gráficos e já modificar de acordo com a não importância de variáveis do melhor modelo.
```{r}
ridge <- ggplot(varImp(model.cv.ridge)) + 
  labs(title="Importância de variáveis (Ridge)", x="Variável", y="Importância")

ridge
```

Com Ridge,as variáveis de `recursos_de_outros_candidatos.comites` e `recursos_proprios` não tiveram importância. Assim como mais abaixo veremos que em Lasso elas também não são importantes.

```{r}
lasso <- ggplot(varImp(model.cv.lasso)) +
  labs(title="Importância de variáveis (Ridge)", x="Variável", y="Importância")
lasso
dataVotos.treino.lasso <- dataVotos.treino %>%
  select(-recursos_de_outros_candidatos.comites,recursos_proprios)
```


**Re-treino do melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada)**    

Um pequeno resumo do que veremos mais abaixo:  

| . | Treino | Teste | Completo |  
|:---------:|:------:|:------:|:------:|
| RSME | 36153.43 | 24216.11 | 33387.62 | 

É possível então perceber que o RSME do nosso dado de treino está próximo ao completo.  

Nosso melhor modelo é o Lasso e retreinando ele temos:

```{r}
data.model.lasso <- train(votos ~.,
                    data = dataVotos.treino.lasso,
                    method = "lasso"
                    )
model.cv.lasso <- train(votos ~ .,
               data = dataVotos.treino.lasso,
               method = "lasso",
               preProcess = c('scale', 'center', 'nzv'),
               tuneLength = 5
               )
lasso.pred <- predict(model.cv.lasso, dataVotos.treino)
lasso.rmse <- rmse(lasso.pred - dataVotos.treino$votos)
lasso.rmse
```

O valor do RMSE foi menor que o anterior `RSME = 36153.43`. De forma geral, a mudança para com a validação cruzada é muito pequena porque esse método não altera o resultado dos testes.  

Agora, com os dados de teste:

```{r}
dataVotos.lasso <- dataVotos.teste %>%
  select(-recursos_de_outros_candidatos.comites,recursos_proprios)

data.model.lasso <- train(votos ~.,
                    data = dataVotos.lasso,
                    method = "lasso"
                    )
model.cv.lasso <- train(votos ~ .,
               data = dataVotos.lasso,
               method = "lasso",
               preProcess = c('scale', 'center', 'nzv'),
               tuneLength = 5
               )
lasso.pred <- predict(model.cv.lasso, dataVotos.teste)
lasso.rmse <- rmse(lasso.pred - dataVotos.teste$votos)
lasso.rmse

```

E, com todos os dados:

```{r}
dataVotos.lasso <- dataVotos.ajustado %>%
  select(-recursos_de_outros_candidatos.comites,recursos_proprios)

data.model.lasso <- train(votos ~.,
                    data = dataVotos.lasso,
                    method = "lasso"
                    )
model.cv.lasso <- train(votos ~ .,
               data = dataVotos.lasso,
               method = "lasso",
               preProcess = c('scale', 'center', 'nzv'),
               tuneLength = 5
               )
lasso.pred <- predict(model.cv.lasso, dataVotos.ajustado)
lasso.rmse <- rmse(lasso.pred - dataVotos.ajustado$votos)
lasso.rmse

```



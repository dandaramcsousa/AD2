---
title: "Predição de Deputados Eleitos 2014"
author: "Dandara Sousa"
date: "26 de fevereiro de 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(readr)
library(dplyr) 
library(ggplot2)


library(caret)

theme_set(theme_minimal())
```


```{r}
data <- read.csv("train.csv")
test <- read.csv("test.csv")
submission <- read.csv("sample_submission.csv")

#criar partição
dataPartition <- createDataPartition(y = data$situacao_final, p=0.75, list=FALSE);
data.train <- data[dataPartition, ]
data.test <- data[-dataPartition, ]
```

1. Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos colaterais o desbalanceamento de classes pode causar no classificador?

Como visto abaixo, a classe marjoritária é a de não eleitos. Sendo assim, há um desbalanceamento onde eleitos são apenas cerca de 10% dos dados. Isso pode causar para o modelo uma desigualdade na hora de aprender a classificar o resultado final. Para isso, mais abaixo usaremos uma função para eliminar aleatoriamente linhas de deputados não eleitos igualando mais a situação.

```{r}
n_eleitos <- data %>% filter(situacao_final == "eleito") %>% nrow()
n_neleitos <- data %>% filter(situacao_final == "nao_eleito") %>% nrow()

df = data.frame(situacao=c("eleito","não eleito"),count = c(n_eleitos, n_neleitos))

ggplot(df,aes(x="", y=count , fill= situacao)) + 
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start=0)
  
```

```{r}
formula = as.formula(situacao_final ~ partido + descricao_cor_raca + sexo, total_despesa)

fitControl <- trainControl(method = "repeatedcv",
                           search = "random",
                           sampling = "up"
                           )
model <- train(form =formula,
               data = data.train,
               method = "LogitBoost",
               trControl = fitControl,
               family="binomial",
               na.action = na.omit
               )

```

#oversampling #undersampling
#package:unbalance

```{r}
# variáveis envolvidas no modelo

```


>Treine: um modelo de regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo. 

>Reporte acurácia, precision, recall e f-measure no treino e validação. Como você avalia os resultados? Justifique sua resposta.

>Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? Crie pelo menos um novo atributo que não está nos dados originais e estude o impacto desse atributo

>Envie seus melhores modelos à competição do Kaggle. Sugestões abaixo:
   Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting)
   Crie novos atributos.
